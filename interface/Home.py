# interface/Home.py
from __future__ import annotations
import re
import os, sys, json
from pathlib import Path
from typing import List, Dict, Any
import streamlit as st
import numpy as np
import textwrap
import html
import time
from streamlit_cookies_manager import EncryptedCookieManager
from streamlit.components.v1 import html as st_html

# ------------------ è½»é‡è·¯å¾„é…ç½®ï¼ˆé¿å…å¯¼å…¥é‡æ¨¡å—ï¼‰ ------------------

st.markdown("""
<style>
/* ma_ui_css_v2 */

/* MA button warm color (orange) */
button[title="Multi-agent Arbitration"] {
  background: linear-gradient(90deg, #ff9f1c, #ffbf69) !important;
  color: #1b1b1b !important;
  border: 1px solid rgba(255,255,255,0.18) !important;
}
button[title="Multi-agent Arbitration"]:hover {
  filter: brightness(1.03);
}

/* Close button smaller to match caption */
button[title="Close MA panel"] {
  padding: 0.18rem 0.55rem !important;
  font-size: 0.86rem !important;
  line-height: 1.1 !important;
}
</style>
""", unsafe_allow_html=True)

REPO_ROOT = Path(__file__).resolve().parents[1]
INDEX_DIR  = REPO_ROOT / "data" / "index"

# === Telemetryï¼šä» core ç›®å½•å¼•å…¥ ===
CORE_DIR = REPO_ROOT / "core"
if str(CORE_DIR) not in sys.path:
    sys.path.append(str(CORE_DIR))

import importlib
import telemetry as _telemetry
importlib.reload(_telemetry)

from telemetry import (
    ensure_schema as log_ensure,
    start_query, finish_query,
    save_answer, set_reaction,
)

from ma_arbitration import run_ma_for_ui, default_llm_ma_dir
set_hit_reaction = getattr(_telemetry, "set_hit_reaction", lambda *args, **kwargs: None)

log_ensure()  # å»ºè¡¨ï¼ˆå­˜åœ¨åˆ™è·³è¿‡ï¼‰

# æ‡’åŠ è½½ + ç¼“å­˜ï¼šæ¨¡å‹ä¸ç´¢å¼•/å…ƒæ•°æ®ï¼Œä»…åœ¨æ£€ç´¢æ—¶è§¦å‘
@st.cache_resource(show_spinner=False)
def _load_model_cached(name: str):
    from sentence_transformers import SentenceTransformer
    device = "cuda" if os.environ.get("CUDA_VISIBLE_DEVICES") not in (None, "", "-1") else "cpu"
    return SentenceTransformer(name, device=device)

@st.cache_data(show_spinner=False)
def _load_meta_cached(p: Path, mtime: float, size: int) -> List[Dict[str, Any]]:
    if not p.exists() or size == 0:
        return []
    rows: List[Dict[str, Any]] = []
    with p.open("r", encoding="utf-8") as f:
        for line in f:
            try:
                rows.append(json.loads(line))
            except Exception:
                pass
    return rows

@st.cache_resource(show_spinner=False)
def _load_faiss_cached(path: Path, mtime: float, size: int):
    import faiss
    if not path.exists() or size == 0:
        return None
    return faiss.read_index(str(path))

def _ensure_index_ready():
    meta_file = INDEX_DIR / "meta.jsonl"
    idx_file  = INDEX_DIR / "faiss.index"
    meta_stat = meta_file.stat() if meta_file.exists() else None
    idx_stat  = idx_file.stat()  if idx_file.exists()  else None

    st.session_state["records"] = _load_meta_cached(
        meta_file,
        meta_stat.st_mtime if meta_stat else 0.0,
        meta_stat.st_size  if meta_stat else 0,
    )
    st.session_state["index"] = _load_faiss_cached(
        idx_file,
        idx_stat.st_mtime if idx_stat else 0.0,
        idx_stat.st_size  if idx_stat else 0,
    )

# -------------------------------------------------------------------

# â€”â€” å¤„ç†å¼¹çª—å…³é—­ï¼ˆæ–°æ—§ API å…¼å®¹ï¼‰â€”â€”
try:
    qp = st.query_params
    val = qp.get("close_explain", None)
    if val in ("1", ["1"]):
        st.session_state.show_explanation = False
        qp.clear()
except Exception:
    p = st.experimental_get_query_params()
    if p.get("close_explain") in (["1"], "1"):
        st.session_state.show_explanation = False
        st.experimental_set_query_params()

# â€”â€” ç­”æ¡ˆç‚¹èµ/ç‚¹è¸© â€”â€” 
try:
    qp2 = st.query_params
    react = qp2.get("react", None)
    aid_q = qp2.get("aid", None)
    if react and aid_q:
        aid_val = int(aid_q if isinstance(aid_q, str) else aid_q[0])
        up = react in ("up", ["up"])
        user_id = (st.session_state.get("user") or {}).get("id")
        set_reaction(aid_val, user_id, 1 if up else -1)
        qp2.clear()
        st.toast("å·²è®°å½•ï¼šğŸ‘ Helpful" if up else "å·²è®°å½•ï¼šğŸ‘ Unhelpful")
except Exception:
    pass

# â€”â€” Top-K æ¡æ¬¾â€œç›¸å…³/ä¸ç›¸å…³â€ â€”â€” 
try:
    qp3 = st.query_params
    hr = qp3.get("hit_react", None)    # "up" / "down"
    qid_q = qp3.get("qid", None)       # query_id
    clause_q = qp3.get("clause", None) # æ¡æ¬¾å·
    if hr and qid_q and clause_q:
        qid_val = int(qid_q if isinstance(qid_q, str) else qid_q[0])
        clause_val = clause_q if isinstance(clause_q, str) else clause_q[0]
        user_id = (st.session_state.get("user") or {}).get("id")
        set_hit_reaction(qid_val, clause_val, user_id, 1 if hr in ("up", ["up"]) else -1)
        qp3.clear()
        st.toast("Feedback regarding the relevance of this clause has been recorded~")
except Exception:
    pass

st.set_page_config(
    page_title="RAG Construction Assistant",
    page_icon="ğŸ—ï¸",
    layout="centered"
)

# â€”â€” éšè— cookies-manager çš„åŒæ­¥ iframeï¼ˆé¿å…ä¾§æ è«åç©ºç™½ï¼‰â€”â€”
st.markdown("""
<style>
iframe[src*="streamlit_cookies_manager.cookie_manager.sync_cookies"]{
  width:0 !important; height:0 !important; min-height:0 !important;
  display:block !important; visibility:hidden !important;
}
</style>
""", unsafe_allow_html=True)

# â€”â€” Cookie ç®¡ç†å™¨ â€”â€” 
cookies = EncryptedCookieManager(
    prefix="ragca_",
    password=os.getenv("COOKIES_PASSWORD", "RAGCA_DEMO")
)
cookies_ready = cookies.ready()  # åªè¯»çŠ¶æ€ï¼Œä¸å† st.stop()

st.title("ğŸ—ï¸ğŸ” RAG Construction Assistant")
st.caption("Ask questions about building specifications, engineering standards or any construction engineering regulations.")

# â€”â€” è‹¥ session æ²¡æœ‰ userï¼Œåˆ™å°è¯•ä» cookie æ¢å¤
if "user" not in st.session_state:
    u_raw = cookies.get("user") if cookies_ready else None
    if u_raw:
        try:
            st.session_state["user"] = json.loads(u_raw)
        except Exception:
            pass

with st.sidebar:
    model_name = st.selectbox("Embedding Model",
                              ["BAAI/bge-base-zh-v1.5", "BAAI/bge-m3"], index=1)
    topk = st.slider("Top-K", 1, 10, 5, 1)
    st.markdown("---")

    # â€”â€” ä¾§æ è´¦æˆ·åŒº â€”â€” 
    if st.session_state.get("user"):
        u = st.session_state["user"]

        # æ ‡é¢˜ä¸å¤´åƒåŒå—æ¸²æŸ“
        st.markdown(
            f'''
            <div style="margin:0 0 10px 0; line-height:1;">
              <div style="font-size:15px;font-weight:700;color:#e5e7eb;">ğŸ” Account</div>
              <div style="display:flex;align-items:center;gap:10px;margin:14px 0 12px;">
                <img src="https://ragca-project-attachments.oss-ap-northeast-1.aliyuncs.com/default_avatar.png"
                     alt="avatar"
                     style="width:36px;height:36px;border-radius:50%;object-fit:cover;border:3px solid #444;" />
                <div style="line-height:1.2;">
                  <div style="font-size:15px;color:#9ca3af;">Logged inï¼š</div>
                  <div style="font-weight:700;font-size:15px;">{u.get("username","")}</div>
                </div>
              </div>
            </div>
            ''', unsafe_allow_html=True
        )

        if st.button("Log out", key="btn_logout", use_container_width=True):
            # 1) æ¸… session
            st.session_state.pop("user", None)
            # 2) ç«‹åˆ»æ¸… cookieï¼ˆåœ¨ä¾§æ å†…å°±æ‰§è¡Œï¼Œç¡®ä¿ä¸‹ä¸€æ¬¡ rerun ä¸ä¼šè¢«è‡ªåŠ¨æ¢å¤ï¼‰
            try:
                cookies["user"] = ""
                cookies.save()
            except Exception:
                pass
            # 3) rerun
            st.rerun()

    else:
        st.caption("ğŸ” Account")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Log in", key="btn_login", use_container_width=True):
                try:
                    st.switch_page("pages/Auth.py")
                except Exception:
                    st.markdown('[å‰å¾€ç™»å½•/æ³¨å†Œ](pages/Auth.py)')
        with col2:
            if st.button("Register", key="btn_register", use_container_width=True):
                try:
                    st.switch_page("pages/Auth.py")
                except Exception:
                    st.markdown('[å‰å¾€ç™»å½•/æ³¨å†Œ](pages/Auth.py)')

    st.markdown("---")
    st.caption("ğŸ—ï¸  Ask questions about building specifications, engineering standards or any construction engineering regulations.")
    st.markdown(
        """
        <a href="https://github.com/bruce0210/rag_construction_assistant" target="_blank">
            <img src="https://github.com/codespaces/badge.svg" alt="Open in GitHub">
        </a>
        """, unsafe_allow_html=True,
    )

# â€”â€” ä¸»åŒºï¼šä»…å½“å€¼å˜åŒ–æ—¶æ‰å†™ cookieï¼ˆç¨³æ€ï¼›é¿å…é‡å¤æ³¨å…¥ iframeï¼‰â€”â€”
if cookies_ready:
    want = json.dumps(st.session_state["user"], ensure_ascii=False) if "user" in st.session_state else ""
    curr = cookies.get("user") or ""
    if want != curr:
        try:
            cookies["user"] = want
            cookies.save()
        except Exception:
            pass

faiss_path = INDEX_DIR / "faiss.index"
meta_path  = INDEX_DIR / "meta.jsonl"

# ------------------------- UI ä¸å·¥å…·å‡½æ•° --------------------------
_STATUS_MAP = {
    "ç°è¡Œ": ("In Force",  "#16a34a"),
    "åºŸæ­¢": ("Obsolete",  "#B22222"),
}
# è‹±æ–‡å…¥å‚ä¹Ÿèƒ½å…¼å®¹
_EN2CN = {
    "in force": "ç°è¡Œ",
    "active":   "ç°è¡Œ",
    "obsolete": "åºŸæ­¢",
    "withdrawn":"åºŸæ­¢",
}

def _status_badge(status: str) -> str:
    """
    å…¥å‚å¯ä»¥æ˜¯ä¸­æ–‡(ç°è¡Œ/åºŸæ­¢)æˆ–è‹±æ–‡(In Force/Obsolete)ã€‚
    å‰ç«¯ç»Ÿä¸€æ˜¾ç¤ºè‹±æ–‡ï¼Œå¹¶æŒ‰è§„èŒƒç€è‰²ã€‚
    """
    cn = status if status in _STATUS_MAP else _EN2CN.get(status.lower(), "")
    if cn in _STATUS_MAP:
        label, color = _STATUS_MAP[cn]
    else:
        label, color = (status or "Unknown"), "#6b7280"

    return (
        f'<span style="background:{color};color:#fff;'
        f'padding:2px 8px;border-radius:6px;font-size:12px;">{label}</span>'
    )


def _doc_title_and_status(src: str) -> tuple[str, str]:
    """
    ä»æ–‡ä»¶åä¸­æå–æ ‡é¢˜ä¸çŠ¶æ€ï¼š
    - æ”¯æŒä¸­æ–‡â€œç°è¡Œ/åºŸæ­¢â€ï¼Œä»¥åŠå¸¦æ‹¬å·çš„ç»“å°¾ï¼ˆå¦‚ï¼š(...)(ç°è¡Œ) / ï¼ˆåºŸæ­¢ï¼‰ï¼‰
    - ä»å…¼å®¹åŸæ¥çš„â€œç»“å°¾ä¸¤ä¸ªå­—â€å†™æ³•
    è¿”å›çš„ status ä¸ºè‹±æ–‡ï¼Œä»¥ä¾¿ç›´æ¥ç”¨äº UI æ˜¾ç¤ºã€‚
    """
    name = src.split("_", 1)[-1] if "_" in src else src
    no_ext = name[:-5] if name.lower().endswith(".docx") else name

    # 1) ä¼˜å…ˆåŒ¹é…ç»“å°¾æ‹¬å·ä¸­çš„çŠ¶æ€ï¼š(...)(ç°è¡Œ)/(åºŸæ­¢)
    m = re.search(r"[ï¼ˆ(]?(ç°è¡Œ|åºŸæ­¢)[)ï¼‰]?$", no_ext)
    if m:
        status_cn = m.group(1)
        title = re.sub(r"[ï¼ˆ(]?(ç°è¡Œ|åºŸæ­¢)[)ï¼‰]?$", "", no_ext).rstrip(" -_[]ï¼ˆï¼‰()")
    else:
        # 2) å›é€€åˆ°åŸé€»è¾‘ï¼šç»“å°¾ä¸¤ä¸ªå­—
        tail2 = no_ext[-2:] if len(no_ext) >= 2 else ""
        if tail2 in ("ç°è¡Œ", "åºŸæ­¢"):
            status_cn = tail2
            title = no_ext[:-2].rstrip(" -_[]ï¼ˆï¼‰()")
        else:
            status_cn = ""
            title = no_ext

    status_en = _STATUS_MAP[status_cn][0] if status_cn else ""
    return title, status_en

def render_clause_text(text: str):
    """æŠŠæ¡æ–‡æ­£æ–‡ä¸â€œæ¡æ–‡è¯´æ˜ï¼šâ€åˆ†å¼€å±•ç¤ºï¼Œå¹¶ç»™è¯´æ˜åŠ ç´«è‰²åº•ã€‚"""
    if not text:
        return
    import re
    s = str(text).strip()
    parts = re.split(r'\s*æ¡æ–‡è¯´æ˜\s*[:ï¼š]\s*', s, maxsplit=1)
    if len(parts) == 2:
        main, note = parts[0], parts[1]
        st.markdown(main)
        st.markdown(
            f'''
            <div style="margin-top:8px; line-height:1.7;">
              <span style="background:#7c3aed; color:#fff; padding:2px 8px; border-radius:6px; font-size:12px;">
                Explanation of the Provisions
              </span>
              <span style="margin-left:.5rem;">{note.strip()}</span>
            </div>
            ''', unsafe_allow_html=True
        )
    else:
        st.markdown(s)

# â€”â€” æŠ½æˆå‡½æ•°ï¼šå‘½ä¸­æ¸²æŸ“ï¼ˆæŒ‰é’®é—´è·åŠ å¤§ï¼‰â€”â€”
def render_hits(hits: list[dict]):
    if not hits:
        return
    for i, r in enumerate(hits, 1):
        with st.container(border=True):
            similarity = r.get("_score", 0.0) * 100
            st.markdown(f"**Top {i}** Â· Semantic Similarity={similarity:.2f}%")
            render_clause_text(r.get("text"))
            media = r.get("media") or []
            if isinstance(media, list) and media:
                for url in media:
                    st.image(url, use_container_width=True)
            title, status = _doc_title_and_status(r.get("source",""))
            badge = _status_badge(status) if status else ""
            st.markdown("---")
            st.markdown(f"Source Standard: ã€Š{title}ã€‹", unsafe_allow_html=True)
            st.markdown(f"Status: {badge}", unsafe_allow_html=True)

            # Top-K ç›¸å…³æ€§åé¦ˆï¼ˆä¸åº•éƒ¨è¾¹æ¡†ç•™å‡ºç©ºé—´ï¼‰
            qid_for_ui = st.session_state.get("last_query_id")
            cl_no = (r.get("clause_no") or "").strip()
            if qid_for_ui and cl_no:
                st.markdown(
                    f'''
                    <div style="margin:12px 0 8px 0; display:flex; gap:10px;">
                      <a href="./?hit_react=up&qid={qid_for_ui}&clause={cl_no}" target="_self"
                         style="text-decoration:none; background:#065f46; color:#fff;
                                padding:2px 6px; border-radius:6px; font-size:12px;">ğŸ‘ Related</a>
                      <a href="./?hit_react=down&qid={qid_for_ui}&clause={cl_no}" target="_self"
                         style="text-decoration:none; background:#7f1d1d; color:#fff;
                                padding:2px 6px; border-radius:6px; font-size:12px;">ğŸ‘ Unrelated</a>
                    </div>
                    ''', unsafe_allow_html=True
                )

def search(q: str, k: int):
    _ensure_index_ready()
    records = st.session_state.get("records", [])
    index = st.session_state.get("index", None)
    if index is None or not records:
        return []
    embedder = _load_model_cached(model_name)
    vec = embedder.encode([q], normalize_embeddings=True).astype("float32")
    import faiss
    D, I = index.search(vec, k)
    out = []
    for rank, idx in enumerate(I[0], 1):
        if 0 <= idx < len(records):
            r = dict(records[idx])
            r["_score"] = float(D[0][rank-1])
            out.append(r)
    return out

# ---------------------- OpenAIï¼ˆLLM è§£è¯»ï¼‰ ----------------
def llm_answer(query: str, hits: list[dict], level: str = "æ ‡å‡†") -> str:
    """ä¸¥æ ¼â€œæœ‰æ®å¯æŸ¥â€åœ°ç”Ÿæˆå›ç­”ã€‚"""
    use_n = min(5, len(hits))
    ctx_blocks = []
    for r in hits[:use_n]:
        title, status = _doc_title_and_status(r.get("source",""))
        media = r.get("media") or []
        ctx_blocks.append({
            "clause_no": r.get("clause_no",""),
            "title": title,
            "status": status,
            "text": (r.get("text") or "").strip(),
            "media": media[:5],
        })

    if level == "Brief Mode":
        length_hint = "ç›®æ ‡é•¿åº¦ï¼šçº¦150â€“250å­—ã€‚"; max_tokens = 350
        structure = ("ã€ç»“è®ºã€‘ä¸€å¥è¯å›ç­”ï¼›\n"
                     "ã€ä¾æ®ã€‘2â€“4æ¡ï¼Œé€æ¡æ ‡æ³¨ï¼ˆæ¡æ¬¾å·ï½œè§„èŒƒåå…¨ç§°ï¼‰ï¼›\n"
                     "ã€æ³¨æ„äº‹é¡¹ã€‘å¦‚æœ‰åˆ™åˆ—å‡ºï¼›\n")
    elif level == "Advanced Mode":
        length_hint = "ç›®æ ‡é•¿åº¦ï¼šçº¦600â€“900å­—ï¼Œæ‹’ç»ç©ºè¯å¥—è¯ã€‚"; max_tokens = 950
        structure = ("ã€ç»“è®ºã€‘å…ˆç»™å‡ºæ˜ç¡®æ•°å€¼/åˆ¤æ–­ï¼›\n"
                     "ã€æ¡æ¬¾é‡Šä¹‰ã€‘è§£é‡Šå…³é”®æœ¯è¯­ä¸é˜ˆå€¼å«ä¹‰ï¼›\n"
                     "ã€é€‚ç”¨èŒƒå›´/è¾¹ç•Œä¸ä¾‹å¤–ã€‘æŒ‡å‡ºé€‚ç”¨å¯¹è±¡ä¸é™åˆ¶ï¼›\n"
                     "ã€ä¾æ®ã€‘é€æ¡åˆ—å‡ºå¹¶æ ‡æ³¨ï¼›\n"
                     "ã€è®¡ç®—æˆ–æ ¡æ ¸ç¤ºä¾‹ã€‘å¦‚é€‚ç”¨ï¼›\n"
                     "ã€å®æ–½å»ºè®®/é£é™©æç¤ºã€‘2â€“4 æ¡ï¼›\n")
    else:
        length_hint = "ç›®æ ‡é•¿åº¦ï¼šçº¦300â€“500å­—ã€‚"; max_tokens = 650
        structure = ("ã€ç»“è®ºã€‘ä¸€å¥è¯å›ç­”å¹¶ç»™å‡ºå…³é”®æ•°å€¼ï¼›\n"
                     "ã€æ¡æ¬¾é‡Šä¹‰ã€‘å·¥ç¨‹è¡¨è¿°ï¼›\n"
                     "ã€ä¾æ®ã€‘é€æ¡åˆ—å‡ºå¹¶æ ‡æ³¨ï¼›\n"
                     "ã€æ³¨æ„äº‹é¡¹ã€‘åˆ—å¸¸è§è¾¹ç•Œï¼›\n")

    sys_prompt = (
        "ä½ æ˜¯å»ºç­‘å·¥ç¨‹è§„èŒƒæ£€ç´¢åŠ©æ‰‹ï¼Œä¸¥æ ¼åŸºäºæˆ‘æä¾›çš„â€œå‘½ä¸­æ–‡æœ¬â€å›ç­”ã€‚"
        "ä¸å¾—è‡†é€ æœªå‡ºç°çš„æ•°å€¼/æ¡ä»¶ï¼›è‹¥è¯æ®ä¸è¶³å¿…é¡»ç›´æ¥è¯´æ˜â€œä¾æ®ä¸è¶³â€ã€‚\n"
        "å†™ä½œè¦æ±‚ï¼š\n"
        "- ä¸­æ–‡è¾“å‡ºï¼Œæœ¯è¯­å‡†ç¡®ã€å¯æ‰§è¡Œï¼›\n"
        "- ç”¨ç¼–å·æˆ–çŸ­å°æ ‡é¢˜ç»„ç»‡ï¼›\n"
        "- æ¯æ¡ä¾æ®æœ«å°¾æ ‡æ³¨ï¼ˆæ¡æ¬¾å·ï½œè§„èŒƒåå…¨ç§°ï¼‰ï¼›\n"
        f"- {length_hint}\n"
        f"{structure}"
    )

    from openai import OpenAI
    client = OpenAI(api_key=st.secrets["openai"]["api_key"])
    payload = {"query": query, "hits": ctx_blocks}
    resp = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        max_tokens=max_tokens,
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": json.dumps(payload, ensure_ascii=False)},
        ],
    )
    return resp.choices[0].message.content.strip()
# -------------------------------------------------------------------

# ---- ä» Prompt Template é¡µé¢å¸¦æ¥çš„é¢„å¡«æŸ¥è¯¢ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰ ----
prefill = st.session_state.pop("home_query_prefill", "")  # è¯»å®Œå³åˆ ï¼Œé˜²æ­¢è¦†ç›–

# é¦–æ¬¡è¿›å…¥æœ¬é¡µæ—¶ï¼Œç”¨é¢„å¡«æˆ–é»˜è®¤æ–‡æ¡ˆåˆå§‹åŒ–è¾“å…¥æ¡†çš„ session çŠ¶æ€
if "query" not in st.session_state:
    st.session_state["query"] = prefill or "Search: 'How are fire hazards in production classified?' Try it..."

# ç»‘å®šåˆ° session çš„è¾“å…¥æ¡†ï¼ˆä¸è¦å†ä¼  valueï¼‰
st.text_input(
    "ğŸ‘·â€â™‚ï¸How can I help you with your construction project today?",
    key="query"
)

query = st.session_state["query"]

# query = st.text_input("ğŸ‘·â€â™‚ï¸How can I help you with your construction project today?", "Search: What is BIM? Try it...")
col_go, col_gpt, col_cfg, col_ma = st.columns([0.8, 0.85, 0.3, 0.9])
with col_go:
    auto_go = bool(prefill) and not st.session_state.get("auto_go_ran")
    if auto_go:
        st.session_state["auto_go_ran"] = True
    go = st.button("ğŸš€ Go!", type="primary", use_container_width=True) or auto_go
with col_gpt:
    explain_btn = st.button("ğŸ§‘â€ Let Prof.LLM Explain", type="secondary", use_container_width=True)
with col_cfg:
    if "detail_level" not in st.session_state:
        st.session_state.detail_level = "Standard Mode"
    if hasattr(st, "popover"):
        with st.popover("âš™ï¸"):
            st.session_state.detail_level = st.radio(
                "Choose the depth of interpretation", ["Brief Mode", "Standard Mode", "Advanced Mode"], index=["Brief Mode","Standard Mode","Advanced Mode"].index(st.session_state.detail_level)
            )
    else:
        with st.expander("âš™ï¸"):
            st.session_state.detail_level = st.radio(
                "Choose the depth of interpretation", ["Brief Mode", "Standard Mode", "Advanced Mode"], index=["Brief Mode","Standard Mode","Advanced Mode"].index(st.session_state.detail_level)
            )
with col_ma:
        ma_btn = st.button("ğŸ§© Multi-agent Arbitration", type="secondary", use_container_width=True)
ma_panel_slot = st.container()  # MA panel fixed under buttons
# â€”â€” å›ºå®šâ€œè§£è¯»â€spinner çš„ä½ç½®ï¼ˆè¾“å…¥æ¡†ä¸‹æ–¹ï¼‰
explain_spinner_slot = st.empty()
ma_spinner_slot = st.empty()

if "show_explanation" not in st.session_state:
    st.session_state.show_explanation = False
if "explanation_text" not in st.session_state:
    st.session_state.explanation_text = ""
if "last_query_id" not in st.session_state:
    st.session_state.last_query_id = None
if "last_answer_id" not in st.session_state:
    st.session_state.last_answer_id = None
if "ma_show" not in st.session_state:
    st.session_state.ma_show = False
if "ma_result" not in st.session_state:
    st.session_state.ma_result = None
if "ma_error" not in st.session_state:
    st.session_state.ma_error = ""
if "ma_answer_id" not in st.session_state:
    st.session_state.ma_answer_id = None

if go and query.strip():
    user_id = (st.session_state.get("user") or {}).get("id")
    qid = start_query(user_id, query.strip(), topk, model_name, page="home")
    st.session_state.last_query_id = qid
    t0 = time.perf_counter()

    with st.spinner("Searching..."):
        hits = search(query.strip(), topk)

    latency_ms = int((time.perf_counter() - t0) * 1000)
    top_clause_nos = []
    try:
        top_clause_nos = [ (r.get("clause_no") or "").strip() for r in (hits or []) ]
        top_clause_nos = [x for x in top_clause_nos if x]
    except Exception:
        pass
    finish_query(qid, n_hits=len(hits or []), latency_ms=latency_ms,
                 top_clause_nos=top_clause_nos)

    SIM_THRESHOLD = 50.0
    filtered_hits = [r for r in hits if r.get("_score", 0.0) * 100 >= SIM_THRESHOLD]
    st.session_state["last_hits"] = filtered_hits

    if not hits:
        st.info("Oh... No results were found (Please try rephrasing your question~)")
    elif not filtered_hits:
        st.info("The semantic similarity is too low... Please try a different way of asking~")
    else:
        render_hits(filtered_hits)

# â€”â€” é Go! çš„ rerunï¼ˆæ¯”å¦‚ç‚¹äº†ç›¸å…³/ä¸ç›¸å…³ï¼‰ä¹Ÿä¿ç•™å‘½ä¸­åˆ—è¡¨ â€”â€” 
elif st.session_state.get("last_hits"):
    render_hits(st.session_state["last_hits"])

# â€”â€” è§£è¯»ï¼šspinner å‡ºç°åœ¨è¾“å…¥æ¡†ä¸‹æ–¹ï¼ˆé€šè¿‡å ä½å®¹å™¨ï¼‰â€”â€”
if explain_btn and query.strip():
    with explain_spinner_slot.container():
        prof_llm_slot = st.empty()
        # prof_llm_slot.info("Prof.LLM: Searching...")
        with st.spinner("Searching..."):
            hits_for_llm = st.session_state.get("last_hits")
            if not hits_for_llm:
                raw_hits = search(query.strip(), topk)
                SIM_THRESHOLD = 60.0
                hits_for_llm = [r for r in raw_hits if r.get("_score", 0.0) * 100 >= SIM_THRESHOLD]
                st.session_state["last_hits"] = hits_for_llm

            if hits_for_llm:
                try:
                    explanation = llm_answer(query.strip(), hits_for_llm, st.session_state.detail_level)
                    st.session_state.explanation_text = explanation
                    st.session_state.show_explanation = True

                    if not st.session_state.get("last_query_id"):
                        user_id = (st.session_state.get("user") or {}).get("id")
                        qid_tmp = start_query(user_id, query.strip(), topk, model_name, page="home")
                        clause_nos_for_llm = []
                        try:
                            clause_nos_for_llm = [ (r.get("clause_no") or "").strip() for r in (hits_for_llm or []) ]
                            clause_nos_for_llm = [x for x in clause_nos_for_llm if x]
                        except Exception:
                            pass
                        finish_query(qid_tmp, n_hits=len(hits_for_llm or []), latency_ms=None,
                                     top_clause_nos=clause_nos_for_llm)
                        st.session_state.last_query_id = qid_tmp

                    ev = {
                        "clause_nos": [ (r.get("clause_no") or "").strip() for r in (hits_for_llm or [])[:5] ],
                        "scores":     [ float(r.get("_score", 0.0)) for r in (hits_for_llm or [])[:5] ],
                    }
                    aid = save_answer(st.session_state.last_query_id, explanation, ev)
                    st.session_state.last_answer_id = aid

                except Exception as e:
                    st.error(f"The engineer is currently making the necessary repairs and will finish soon.ï¼š{e}")
            else:
                st.warning("The semantic similarity is too low... Please try a different way of asking~")
        prof_llm_slot.empty()
    # è§£è¯»ç»“æŸåæ¸…æ‰ spinner
    explain_spinner_slot.empty()





# â€”â€” å¤šæ™ºèƒ½ä½“ä»²è£ï¼ˆå±•ç¤º 6 ä¸“å®¶ + ä»²è£ï¼›æœ¬é˜¶æ®µå…ˆä¸è½åº“ï¼‰â€”â€”
if "ma_show" not in st.session_state:
    st.session_state.ma_show = False
if "ma_result" not in st.session_state:
    st.session_state.ma_result = None
if "ma_error" not in st.session_state:
    st.session_state.ma_error = ""

# å›ºå®šå±•ç¤ºä½ç½®ï¼ˆæŒ‰é’®ä¸‹æ–¹ï¼‰
if "ma_panel_slot" not in globals():
    ma_panel_slot = st.container()
if "ma_spinner_slot" not in globals():
    ma_spinner_slot = st.empty()

# ma_btn å¯èƒ½åœ¨æŸäº›åˆ†æ”¯æœªå®šä¹‰ï¼Œè¿™é‡Œåšä¿æŠ¤
try:
    _ma_clicked = bool(ma_btn) and bool(query.strip())
except Exception:
    _ma_clicked = False

# ç‚¹å‡»æŒ‰é’®ï¼šé‡æ–°è·‘ä¸€æ¬¡ MAï¼ˆä½¿ç”¨å½“å‰è¾“å…¥æ¡† queryï¼‰
if _ma_clicked:
    # --- [MA][DB] scheme A: dedicated query_id for this MA run ---
    user_id = (st.session_state.get("user") or {}).get("id")
    ma_model_name = f"{model_name}+MA" if "+MA" not in str(model_name) else str(model_name)
    ma_qid = start_query(user_id, query.strip(), 50, ma_model_name, page="home")
    st.session_state.ma_query_id = ma_qid
    ma_t0 = time.perf_counter()
    st.session_state.ma_show = True
    st.session_state.ma_error = ""
    st.session_state.ma_result = None

    with ma_spinner_slot.container():
        with st.spinner("Running multi-agent arbitration..."):
            try:
                hits_for_ma = search(query.strip(), 50)  # åç«¯é»˜è®¤ Top 50 candidates
                if not hits_for_ma:
                    raise RuntimeError("No candidates were found. Please try rephrasing your question.")
                llm_ma_dir = default_llm_ma_dir(REPO_ROOT)
# [MA] load env.sh
                # Load API keys into current Streamlit process (strip quotes)
                import os
                from pathlib import Path as _Path
                _env_sh = _Path(llm_ma_dir) / "configs" / "env.sh"
                import os
                os.environ.setdefault("DASHSCOPE_BASE_URL", "https://dashscope-intl.aliyuncs.com/compatible-mode/v1")
                if _env_sh.exists():
                    for _raw in _env_sh.read_text(encoding="utf-8", errors="ignore").splitlines():
                        _line = _raw.strip()
                        if (not _line) or _line.startswith("#"):
                            continue
                        if _line.startswith("export "):
                            _line = _line[len("export "):].strip()
                        if "=" not in _line:
                            continue
                        _k, _v = _line.split("=", 1)
                        _k = _k.strip()
                        _v = _v.strip().strip('"').strip("'").strip()
                        if _k:
                            os.environ[_k] = _v

                ma_out = run_ma_for_ui(query.strip(), hits_for_ma, llm_ma_dir=llm_ma_dir, candidates_topn=50)
                st.session_state.ma_result = ma_out

                # --- [MA][DB] persist final answer + evidence into PGSQL ---
                try:
                    _final = (ma_out or {}).get("final") or {}
                    _final_answer = _final.get("final_answer") or ""
                    _final_clause_ids = _final.get("final_clause_ids") or []
                    _ev = (ma_out or {}).get("evidence_bundle") or {}
                    if isinstance(_ev, dict):
                        _ev.setdefault("triggered", (ma_out or {}).get("triggered"))
                        _ev.setdefault("used_models", (ma_out or {}).get("used_models"))
                    # normalize to JSON-serializable primitives (telemetry.save_answer uses json.dumps)
                    _ev = json.loads(json.dumps(_ev, ensure_ascii=False, default=str))
                    st.session_state.ma_answer_id = save_answer(ma_qid, _final_answer, _ev)

                    _top_hits = [str(x).strip() for x in (_final_clause_ids or []) if str(x).strip()]
                    if not _top_hits:
                        _top_hits = [str((r.get("clause_no") or r.get("clause_id") or "")).strip() for r in (hits_for_ma or [])]
                        _top_hits = [x for x in _top_hits if x]
                    finish_query(
                        ma_qid,
                        n_hits=len(hits_for_ma or []),
                        latency_ms=int((time.perf_counter() - ma_t0) * 1000),
                        top_clause_nos=_top_hits,
                    )
                except Exception as _db_e:
                    st.session_state.ma_error = (st.session_state.ma_error + f" | DB persist failed: {_db_e}").strip(" |")
            except Exception as e:
                st.session_state.ma_error = str(e)
                try:
                    finish_query(
                        ma_qid,
                        n_hits=0,
                        latency_ms=int((time.perf_counter() - ma_t0) * 1000),
                        top_clause_nos=[],
                    )
                except Exception:
                    pass

    ma_spinner_slot.empty()

# å±•ç¤ºé¢æ¿ï¼š6 ä¸“å®¶è¾©è®º + ä»²è£
if st.session_state.get("ma_show", False):
    with ma_panel_slot:
        with st.expander("ğŸ§© Multi-agent Arbitration (Debate + Arbitration)", expanded=True):
            col_close, col_note = st.columns([2, 10])
            with col_close:
                if st.button("âŒ Close", key="ma_close_panel", help="Close MA panel"):
                    st.session_state.ma_show = False
                    st.session_state.ma_result = None
                    st.session_state.ma_error = ""
            with col_note:
                st.caption("Experts Model: Qwen-max (6 agents) Â· Arbiter Model: OpenAI (GPT-4o)")

            if st.session_state.get("ma_error"):
                st.error(st.session_state.ma_error)
            elif not st.session_state.get("ma_result"):
                st.info("Click the MA button to run arbitration.")
            else:
                ma_out = st.session_state.ma_result or {}
                diag = ma_out.get("trigger_diag") or {}
                triggered = bool(ma_out.get("triggered", False))

                st.markdown(f"**Arbiter triggered:** `{triggered}`")
                if diag.get("trigger_reasons"):
                    st.markdown("**Trigger reasons:** " + ", ".join(diag.get("trigger_reasons", [])))

                final = ma_out.get("final") or {}
                st.markdown("## âœ… Final Decision")
                if final.get("final_answer"):
                    st.success(final["final_answer"])
                else:
                    st.json(final)
                tabs = st.tabs(["arch", "struct", "plumb", "hvac", "elec", "fire", "final_json"])
                expert_list = ma_out.get("experts") or []
                expert_by = {e.get("agent_id"): e for e in expert_list if isinstance(e, dict) and e.get("agent_id")}
                order = ["arch", "struct", "plumb", "hvac", "elec", "fire"]

                for tab, aid in zip(tabs[:6], order):
                    with tab:
                        obj = expert_by.get(aid)
                        if not obj:
                            st.info("No output.")
                        else:
                            st.json(obj)

                with tabs[6]:
                    st.json(final)

# ---- å¼¹çª—ï¼ˆé¡¶å±‚ DOM æ³¨å…¥ï¼Œå›ºå®šåœ¨é¡µé¢ä¸­é—´ï¼›æ— ç¼©è¿›ï¼Œé¿å…è¢« Markdown å½“ä½œä»£ç å—ï¼‰ ----
if st.session_state.get("show_explanation", False):
    if st.button("âŒ Close", key="close_explain_top"):
        st.session_state.show_explanation = False
        st.stop()

    # é®ç½©ï¼ˆé¡¶å±‚ï¼›ä¸æ‹¦æˆªç‚¹å‡»ï¼‰â€”â€” æ³¨æ„æ— ä»»ä½•å‰å¯¼ç©ºæ ¼
    overlay_html = '<div style="position:fixed;inset:0;background:rgba(0,0,0,0.45);z-index:9998;pointer-events:none;"></div>'
    st.markdown(overlay_html, unsafe_allow_html=True)

    # åªè½¬ä¹‰ LLM æ­£æ–‡ï¼ˆä¿ç•™æ¢è¡Œï¼‰
    ex_html = html.escape(st.session_state.explanation_text).replace("\n", "<br/>")

    # åº•éƒ¨æŒ‰é’®ï¼ˆåŸç”Ÿ HTMLï¼‰
    aid_for_ui = st.session_state.get("last_answer_id")
    btns_html = ""
    if aid_for_ui:
        btns_html = (
            f'<div style="margin-top:12px;display:flex;gap:12px;">'
            f'  <a href="./?react=up&aid={aid_for_ui}" target="_self" '
            f'     style="text-decoration:none;background:#065f46;color:#fff;padding:4px 8px;'
            f'            border-radius:8px;font-size:13px;">ğŸ‘ Helpful</a>'
            f'  <a href="./?react=down&aid={aid_for_ui}" target="_self" '
            f'     style="text-decoration:none;background:#7f1d1d;color:#fff;padding:4px 8px;'
            f'            border-radius:8px;font-size:13px;">ğŸ‘ Unhelpful</a>'
            f'</div>'
        )

    # å¼¹çª—ä¸»ä½“ï¼ˆæ— ç¼©è¿›å­—ç¬¦ä¸²ï¼Œç¡®ä¿ä¸æ˜¯ä»£ç å—ï¼‰
    modal_html = (
        '<div style="position:fixed;top:50%;left:50%;transform:translate(-50%,-50%);'
        'background-color:#1e1e1e;padding:28px 28px 24px;border-radius:12px;'
        'box-shadow:0 8px 24px rgba(0,0,0,0.7);z-index:9999;width:min(1250px,96vw);'
        'max-height:84vh;overflow-y:auto;pointer-events:auto;">'
        '  <a href="./?close_explain=1" target="_self" title="å…³é—­" '
        '     style="position:absolute;top:8px;right:12px;text-decoration:none;'
        '            background:#374151;color:#fff;padding:2px 8px;border-radius:8px;'
        '            font-weight:700;line-height:1;">Ã—</a>'
        '  <h3 style="color:#00BFFF;margin:0 0 12px 0;">ğŸ“˜ Explanation from the Prof.LLM </h3>'
        f' <div style="color:white;font-size:15px;line-height:1.7;">{ex_html}</div>'
        f' {btns_html}'
        '</div>'
    )
    st.markdown(modal_html, unsafe_allow_html=True)

    if st.button("Close", key="close_explain_bottom"):
        st.session_state.show_explanation = False
        st.experimental_rerun()